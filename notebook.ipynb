{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn when to buy/sell given observations of recent price history only (the network is let to decide what features are important to extract from the price history)\n",
    "\n",
    "The autocorrelogram is in a sense the \"best\" feature to use as this is the only statistical difference between fractional Brownian motion and regular Brownian motion, for which no trading strategy should be profitable on average.\n",
    "\n",
    "Below we only provide the network policy approximator with the price history, $\\textit{not} $ the autocorrelogram. Therefore the performance of the network is essentially driven by its ability to capture autocorrelation as an important feature and reconstruct autocorrelation from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "from pprint import pprint\n",
    "from pyvirtualdisplay import Display\n",
    "from IPython import display as ipythondisplay\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from env.rl_trading_env import rl_trading_env\n",
    "from agent import *\n",
    "\n",
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV data\n",
    "\n",
    "$H=0.7$ : trend-following signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'fbm_0700.csv'\n",
    "dfs = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Gym environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = rl_trading_env(dfs, \n",
    "                     n_lag=10, \n",
    "                     observe_type='return',\n",
    "                     reward_mode='pnl',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPModel(env.observation_space.shape[0],\n",
    "                 env.action_space.n, \n",
    "                 use_cuda=USE_CUDA,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "gamma = 0.9\n",
    "seed = 1235\n",
    "\n",
    "config = {\n",
    "    'env': env,\n",
    "    'learning_rate': learning_rate,\n",
    "    'seed': seed,\n",
    "    'gamma': gamma,\n",
    "    'verbose': 10,\n",
    "    'max_episode_length': 250,\n",
    "    'use_mean_baseline': True,\n",
    "    'use_cuda': USE_CUDA,\n",
    "    'model': model,\n",
    "}\n",
    "\n",
    "print(\"Current config is:\")\n",
    "pprint(config)\n",
    "\n",
    "agent = REINFORCE(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_start = perf_counter()  \n",
    "agent.train(n_trajectories=15, n_update=2000)\n",
    "t1_stop = perf_counter() \n",
    "print('Elapsed time during training: {:.2f}s'.format(t1_stop-t1_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_trained = agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on new price paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'fbm_0700_test.csv'\n",
    "dfs = pd.read_csv(fname)\n",
    "env = rl_trading_env(dfs, 10)\n",
    "config['env'] = env\n",
    "agent = REINFORCE(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    state = torch.FloatTensor(env.reset())\n",
    "    done = False\n",
    "    PnL = []\n",
    "\n",
    "    while not done:\n",
    "        action = int(agent.model.select_action(state))\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        state = torch.FloatTensor(state)\n",
    "        PnL.append(reward)\n",
    "    plt.plot(np.array(PnL).cumsum())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
